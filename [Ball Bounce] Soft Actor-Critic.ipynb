{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUaLsciZcB6giKsOf+EgYW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuds/rl-mujoco-tennis/blob/main/%5BBall%20Bounce%5D%20Soft%20Actor-Critic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ball Bounce: Soft Actor-Critic (SAC)\n",
        "\n",
        "## Helpful Links\n",
        "https://github.com/denisgriaznov/CustomMuJoCoEnviromentForRL"
      ],
      "metadata": {
        "id": "Z5m28j-y778h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mujoco\n",
        "\n",
        "# Set up GPU rendering.\n",
        "from google.colab import files\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.')\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "# Check if installation was succesful.\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
        "\n",
        "print('Installation successful.')\n",
        "\n",
        "# Other imports and helper functions\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "# Graphics and plotting.\n",
        "print('Installing mediapy:')\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!pip install -q mediapy\n",
        "import mediapy as media\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# More legible printing from numpy.\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n"
      ],
      "metadata": {
        "id": "CRcmb1y7XABJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "id": "r5g-qyU5l1Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium\n",
        "import mujoco\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "import numpy\n",
        "import os\n",
        "import torch\n",
        "import platform\n",
        "from importlib.metadata import version\n",
        "import matplotlib\n",
        "import matplotlib.pyplot\n",
        "from gymnasium import utils\n",
        "from gymnasium.envs.mujoco import MujocoEnv\n",
        "from gymnasium.spaces import Box\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3 import SAC"
      ],
      "metadata": {
        "id": "WY4o6uzNlqb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Python Version: {platform.python_version()}\")\n",
        "print(f\"Torch Version: {version('torch')}\")\n",
        "print(f\"Is Cuda Available: {torch.cuda.is_available()}\")\n",
        "print(f\"Cuda Version: {torch.version.cuda}\")\n",
        "print(f\"Gymnasium Version: {version('gymnasium')}\")\n",
        "print(f\"Numpy Version: {version('numpy')}\")\n",
        "print(f\"Mujoco Version: {version('mujoco')}\")\n",
        "print(f\"Stable-Baselines3 Version: {version('stable-baselines3')}\")\n",
        "print(f\"Matplotlib Version: {version('matplotlib')}\")"
      ],
      "metadata": {
        "id": "W93vyNlZmDW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rl_type = \"SAC\"\n",
        "env_str = \"BallBounce\"\n",
        "log_dir = \"./logs/{}\".format(env_str)\n",
        "name_prefix = \"ball_bounce\""
      ],
      "metadata": {
        "id": "_pWMBaSjbSyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zl8FYadlNQq"
      },
      "outputs": [],
      "source": [
        "class BallBounceEnv(MujocoEnv, utils.EzPickle):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\n",
        "            \"human\",\n",
        "            \"rgb_array\",\n",
        "            \"depth_array\",\n",
        "        ],\n",
        "        \"render_fps\": 100,\n",
        "    }\n",
        "\n",
        "    # set default episode_len for truncate episodes\n",
        "    def __init__(self, episode_len=750, **kwargs):\n",
        "        utils.EzPickle.__init__(self, **kwargs)\n",
        "\n",
        "        self.bounce_count = 0\n",
        "        self.previous_touch_value = 0\n",
        "        # change shape of observation to your observation space size\n",
        "        observation_space = Box(low=-numpy.inf, high=np.inf, shape=(18,), dtype=numpy.float64)\n",
        "        # load your MJCF model with env and choose frames count between actions\n",
        "        MujocoEnv.__init__(\n",
        "            self,\n",
        "            os.path.abspath(f\"/content/{name_prefix}.xml\"),\n",
        "            5,\n",
        "            observation_space=observation_space,\n",
        "            **kwargs\n",
        "        )\n",
        "        self.step_number = 0\n",
        "        self.episode_len = episode_len\n",
        "\n",
        "    # determine the reward depending on observation or other properties of the simulation\n",
        "    def step(self, a):\n",
        "        reward = 0.0\n",
        "        self.do_simulation(a, self.frame_skip)\n",
        "        self.step_number += 1\n",
        "\n",
        "         # Bounce Detection (CRITICAL)\n",
        "        current_touch_value = self.data.sensor(\"touch_sensor\").data[0]\n",
        "        if current_touch_value > 0 and self.previous_touch_value <= 0:  # Check for transition from no contact to contact\n",
        "            self.bounce_count += 1\n",
        "            reward = 1.0\n",
        "        self.previous_touch_value = current_touch_value\n",
        "\n",
        "        obs = self._get_obs()\n",
        "        done = bool(not np.isfinite(obs).all() or (obs[2] < 0))\n",
        "        truncated = self.step_number > self.episode_len\n",
        "        return obs, reward, done, truncated, {}\n",
        "\n",
        "    # define what should happen when the model is reset (at the beginning of each episode)\n",
        "    def reset_model(self):\n",
        "        self.step_number = 0\n",
        "\n",
        "        # for example, noise is added to positions and velocities\n",
        "        qpos = self.init_qpos + self.np_random.uniform(\n",
        "            size=self.model.nq, low=-0.01, high=0.01\n",
        "        )\n",
        "        qvel = self.init_qvel + self.np_random.uniform(\n",
        "            size=self.model.nv, low=-0.01, high=0.01\n",
        "        )\n",
        "        self.set_state(qpos, qvel)\n",
        "        return self._get_obs()\n",
        "\n",
        "    # determine what should be added to the observation\n",
        "    # for example, the velocities and positions of various joints can be obtained through their names, as stated here\n",
        "    def _get_obs(self):\n",
        "        obs = np.concatenate((np.array(self.data.joint(\"ball\").qpos[:3]),\n",
        "                              np.array(self.data.joint(\"ball\").qvel[:3]),\n",
        "                              np.array(self.data.joint(\"rotate_x\").qpos),\n",
        "                              np.array(self.data.joint(\"rotate_x\").qvel),\n",
        "                              np.array(self.data.joint(\"rotate_y\").qpos),\n",
        "                              np.array(self.data.joint(\"rotate_y\").qvel),\n",
        "                              np.array(self.data.joint(\"rotate_z\").qpos),\n",
        "                              np.array(self.data.joint(\"rotate_z\").qvel),\n",
        "                              np.array(self.data.joint(\"slider_x\").qpos),\n",
        "                              np.array(self.data.joint(\"slider_x\").qvel),\n",
        "                              np.array(self.data.joint(\"slider_y\").qpos),\n",
        "                              np.array(self.data.joint(\"slider_y\").qvel),\n",
        "                              np.array(self.data.joint(\"slider_z\").qpos),\n",
        "                              np.array(self.data.joint(\"slider_z\").qvel)), axis=0)\n",
        "        return obs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure environment XML (MuJoCo model) is available\n",
        "xml_content = \"\"\"\n",
        "<mujoco>\n",
        "\t<asset>\n",
        "\t\t<texture name=\"grid\" type=\"2d\" builtin=\"checker\" rgb1=\".1 .2 .3\"\n",
        "     rgb2=\".2 .3 .4\" width=\"300\" height=\"300\" mark=\"none\"/>\n",
        "\t\t<material name=\"grid\" texture=\"grid\" texrepeat=\"1 1\"\n",
        "     texuniform=\"true\" reflectance=\".2\"/>\n",
        "\t</asset>\n",
        "\t<worldbody>\n",
        "\t\t<light name=\"light\" pos=\"0 0 1\"/>\n",
        "\t\t<geom name=\"floor\" type=\"plane\" pos=\"0 0 -.5\" size=\"2 2 .1\" material=\"grid\"/>\n",
        "\t\t<camera name=\"fixed\" pos=\"0 -1.3 .5\" xyaxes=\"1 0 0 0 1 2\"/>\n",
        "\t\t<body name=\"box\" pos=\".2 .2 .1\">\n",
        "\t\t\t<site name=\"bounce_sensor\" pos=\"0 0 0.075\" size=\"0.1 0.1\" type=\"box\" rgba=\"1 0 0 1\"/>\n",
        "\t\t\t<joint name=\"rotate_x\" pos=\"0 0 0\" axis=\"1 0 0\" range=\"-.25 .25\" damping=\"20\" />\n",
        "\t\t\t<joint name=\"rotate_y\" pos=\"0 0 0\" axis=\"0 1 0\" range=\"-.25 .25\" damping=\"20\" />\n",
        "\t\t\t<joint name=\"rotate_z\" pos=\"0 0 0\" axis=\"0 0 1\" range=\"-.25 .25\" damping=\"20\" />\n",
        "\t\t\t<joint axis=\"0 0 1\" limited=\"true\" name=\"slider_z\" range=\"0 1\" type=\"slide\"/>\n",
        "\t\t\t<joint axis=\"0 1 0\" limited=\"true\" name=\"slider_y\" range=\"-.25 .25\" type=\"slide\"/>\n",
        "\t\t\t<joint axis=\"1 0 0\" limited=\"true\" name=\"slider_x\" range=\"-.25 .25\" type=\"slide\"/>\n",
        "\t\t\t<geom name=\"box\" type=\"box\" size=\".2 .2 .02\" rgba=\"1 0 0 1\" solref=\"0.02 0.5\"/>\n",
        "\t\t</body>\n",
        "\t\t<body name=\"ball\" pos=\".2 .2 .4\">\n",
        "\t\t\t<freejoint name=\"ball\"/>\n",
        "\t\t\t<geom name=\"ball\" pos=\"0 0 0\" size=\".05\" rgba=\"0 1 0 1\" solref=\"0.02 0.1\"/>\n",
        "\t\t</body>\n",
        "\t</worldbody>\n",
        "\t<actuator>\n",
        "\t\t<general name=\"act_x\" joint=\"rotate_x\" ctrlrange=\"-1 1\" gainprm=\"1000 0 0\" />\n",
        "\t\t<general name=\"act_y\" joint=\"rotate_y\" ctrlrange=\"-1 1\" gainprm=\"1000 0 0\" />\n",
        "\t\t<general name=\"act_z\" joint=\"rotate_z\" ctrlrange=\"-1 1\" gainprm=\"1000 0 0\" />\n",
        "\t\t<motor ctrllimited=\"true\" ctrlrange=\"-1 1\" gear=\"100\" joint=\"slider_z\" name=\"slider_z\"/>\n",
        "\t\t<motor ctrllimited=\"true\" ctrlrange=\"-1 1\" gear=\"100\" joint=\"slider_y\" name=\"slider_y\"/>\n",
        "\t\t<motor ctrllimited=\"true\" ctrlrange=\"-1 1\" gear=\"100\" joint=\"slider_x\" name=\"slider_x\"/>\n",
        "\t</actuator>\n",
        "\t<sensor>\n",
        "\t\t<touch name=\"touch_sensor\" site=\"bounce_sensor\"/>\n",
        "\t</sensor>\n",
        "</mujoco>\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{name_prefix}.xml\", \"w\") as f:\n",
        "    f.write(xml_content)"
      ],
      "metadata": {
        "id": "WSabiKwgmS-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = BallBounceEnv(render_mode=\"rgb_array\")\n",
        "print(\"Observation Space Size: \", env.observation_space.shape)\n",
        "print('Actions Space: ', env.action_space)\n",
        "env.close()"
      ],
      "metadata": {
        "id": "Wks5iHMc_zz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_env():\n",
        "  env = BallBounceEnv(render_mode=\"rgb_array\")\n",
        "  check_env(env)\n",
        "  return env\n",
        "\n",
        "# Create Training environment\n",
        "env = make_vec_env(make_env, n_envs=4)\n",
        "\n",
        "# Create Evaluation environment\n",
        "env_val = make_vec_env(make_env, n_envs=1)\n",
        "\n",
        "eval_callback = EvalCallback(env_val,\n",
        "                             best_model_save_path=log_dir,\n",
        "                             log_path=log_dir,\n",
        "                             render=False,\n",
        "                             deterministic=True,\n",
        "                             eval_freq=50_000)\n",
        "\n",
        "# learning with tensorboard logging and saving model\n",
        "model = SAC(\"MlpPolicy\",\n",
        "            env,\n",
        "            verbose=0,\n",
        "            tensorboard_log=os.path.join(log_dir, \"tensorboard\"))\n",
        "\n",
        "model.learn(total_timesteps=1_000_000,\n",
        "            log_interval=4,\n",
        "            callback=eval_callback,\n",
        "            progress_bar=True)\n",
        "\n",
        "# Save the model\n",
        "model.save(os.path.join(log_dir, \"final_model\"))\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env)\n",
        "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "\n",
        "env.close()\n",
        "env_val.close()"
      ],
      "metadata": {
        "id": "31kWylPTqRBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Evaluation environment\n",
        "env = BallBounceEnv(render_mode=\"rgb_array\")\n",
        "check_env(env)\n",
        "env = DummyVecEnv([lambda: env])\n",
        "\n",
        "# Load the best model\n",
        "best_model_path = os.path.join(log_dir, \"best_model\")\n",
        "best_model = SAC.load(best_model_path, env=env)\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(best_model, env)\n",
        "print(f\"Best Model - Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "\n",
        "# Record video of the best model\n",
        "env = VecVideoRecorder(env, os.path.join(log_dir, \"videos\"),\n",
        "                       video_length=10_000,\n",
        "                       record_video_trigger=lambda x: x == 0,\n",
        "                       name_prefix=\"best_model_{}\".format(name_prefix))\n",
        "\n",
        "obs = env.reset()\n",
        "for _ in range(10_000):\n",
        "    action, _states = best_model.predict(obs, deterministic=True)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    env.render()\n",
        "    if dones:\n",
        "        break\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "TiwmYjHCasmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the evaluations.npz file\n",
        "data = numpy.load(os.path.join(log_dir, \"evaluations.npz\"))\n",
        "\n",
        "# Extract the relevant data\n",
        "timesteps = data['timesteps']\n",
        "results = data['results']\n",
        "\n",
        "# Calculate the mean and standard deviation of the results\n",
        "mean_results = numpy.mean(results, axis=1)\n",
        "std_results = numpy.std(results, axis=1)\n",
        "\n",
        "# Plot the results\n",
        "matplotlib.pyplot.figure()\n",
        "matplotlib.pyplot.plot(timesteps, mean_results)\n",
        "matplotlib.pyplot.fill_between(timesteps,\n",
        "                               mean_results - std_results,\n",
        "                               mean_results + std_results,\n",
        "                               alpha=0.3)\n",
        "\n",
        "matplotlib.pyplot.xlabel('Timesteps')\n",
        "matplotlib.pyplot.ylabel('Mean Reward')\n",
        "matplotlib.pyplot.title(f\"{rl_type} Performance on {env_str}\")\n",
        "matplotlib.pyplot.show()"
      ],
      "metadata": {
        "id": "eWL1-laWawXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "62HctLv03Ewz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}