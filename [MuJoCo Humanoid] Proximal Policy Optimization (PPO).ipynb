{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvXOBEEr3+RZOK/LH7Vi2U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuds/rl-mujoco-tennis/blob/main/%5BMuJoCo%20Humanoid%5D%20Proximal%20Policy%20Optimization%20(PPO).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvR_VQZbCPW4"
      },
      "outputs": [],
      "source": [
        "!pip install mujoco"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "id": "itOOHUv2CQpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copied from https://colab.research.google.com/github/google-deepmind/mujoco/blob/main/python/tutorial.ipynb\n",
        "\n",
        "# Set up GPU rendering.\n",
        "from google.colab import files\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.')\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "# Check if installation was succesful.\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
        "\n",
        "print('Installation successful.')\n",
        "\n",
        "# Other imports and helper functions\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "# Graphics and plotting.\n",
        "print('Installing mediapy:')\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!pip install -q mediapy\n",
        "import mediapy as media\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# More legible printing from numpy.\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "OFQ4buPiFtVp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium\n",
        "import mujoco\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "import numpy\n",
        "import os\n",
        "import torch\n",
        "import platform\n",
        "from importlib.metadata import version\n",
        "import matplotlib\n",
        "import matplotlib.pyplot"
      ],
      "metadata": {
        "id": "9Hn76GWeCm96"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Python Version: {platform.python_version()}\")\n",
        "print(f\"Torch Version: {version('torch')}\")\n",
        "print(f\"Is Cuda Available: {torch.cuda.is_available()}\")\n",
        "print(f\"Cuda Version: {torch.version.cuda}\")\n",
        "print(f\"Gymnasium Version: {version('gymnasium')}\")\n",
        "print(f\"Numpy Version: {version('numpy')}\")\n",
        "print(f\"Tensorflow Version: {version('tensorflow')}\")\n",
        "print(f\"tqdm Version: {version('tqdm')}\")\n",
        "print(f\"MuJoCo Version: {version('mujoco')}\")\n",
        "print(f\"Stable Baselines3 Version: {version('stable_baselines3')}\")"
      ],
      "metadata": {
        "id": "fZw1FEd7CjKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rl_type = \"PPO\"\n",
        "env_str = \"Humanoid-v4\"\n",
        "log_dir = \"./logs/{}\".format(env_str)\n",
        "name_prefix = \"humanoid\""
      ],
      "metadata": {
        "id": "yLX4MFRvDRQK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Humanoid environment\n",
        "env = make_vec_env(env_str, n_envs=4)\n",
        "\n",
        "# Create the PPO model\n",
        "model = PPO(\n",
        "    policy=\"MlpPolicy\",  # Multi-layer perceptron policy\n",
        "    env=env,\n",
        "    verbose=0,\n",
        "    learning_rate=0.0003,\n",
        "    ent_coef=0.01\n",
        ")\n",
        "\n",
        "eval_callback = EvalCallback(env,\n",
        "                             best_model_save_path=log_dir,\n",
        "                             log_path=log_dir,\n",
        "                             eval_freq=25_000)\n",
        "\n",
        "# Train the model\n",
        "time_steps = 10_000_000\n",
        "model.learn(total_timesteps=time_steps,\n",
        "            callback=eval_callback,\n",
        "            progress_bar=True)\n",
        "\n",
        "# Save the model\n",
        "model.save(os.path.join(log_dir, \"ppo_humanoid\"))\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env)\n",
        "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "id": "4-bIEczMCTwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Evaluation CarRacing environment\n",
        "env = make_vec_env(env_str, n_envs=1, seed=0)\n",
        "\n",
        "# Load the best model\n",
        "best_model_path = os.path.join(log_dir, \"best_model.zip\")\n",
        "best_model = PPO.load(best_model_path, env=env)\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(best_model, env)\n",
        "print(f\"Best Model - Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "\n",
        "# Record video of the best model playing CarRacing\n",
        "env = VecVideoRecorder(env, \"./videos/\",\n",
        "                       video_length=10_000,\n",
        "                       record_video_trigger=lambda x: x == 0,\n",
        "                       name_prefix=\"best_model_{}\".format(name_prefix))\n",
        "\n",
        "obs = env.reset()\n",
        "for _ in range(10_000):\n",
        "    action, _states = best_model.predict(obs, deterministic=True)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    env.render()\n",
        "    if dones:\n",
        "        break\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "YJuhqmXhFTFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the evaluations.npz file\n",
        "data = numpy.load(os.path.join(log_dir, \"evaluations.npz\"))\n",
        "\n",
        "# Extract the relevant data\n",
        "timesteps = data['timesteps']\n",
        "results = data['results']\n",
        "\n",
        "# Calculate the mean and standard deviation of the results\n",
        "mean_results = numpy.mean(results, axis=1)\n",
        "std_results = numpy.std(results, axis=1)\n",
        "\n",
        "# Plot the results\n",
        "matplotlib.pyplot.figure()\n",
        "matplotlib.pyplot.plot(timesteps, mean_results)\n",
        "matplotlib.pyplot.fill_between(timesteps,\n",
        "                               mean_results - std_results,\n",
        "                               mean_results + std_results,\n",
        "                               alpha=0.3)\n",
        "\n",
        "matplotlib.pyplot.xlabel('Timesteps')\n",
        "matplotlib.pyplot.ylabel('Mean Reward')\n",
        "matplotlib.pyplot.title('PPO Performance on CarRacing-v2')\n",
        "matplotlib.pyplot.show()"
      ],
      "metadata": {
        "id": "e8TLXTwaCcqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7OvVEDHF4Sa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}